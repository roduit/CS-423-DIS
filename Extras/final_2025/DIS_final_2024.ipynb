{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1692bdd5-f424-4166-ac56-126ed6eab841",
   "metadata": {},
   "source": [
    "# üìò DIS Final Exam - Fall 2024\n",
    "\n",
    "**üéâ Welcome to DIS Final exam that takes place on the 30th of January 2025.**\n",
    "\n",
    "> Please fill the following info:\n",
    "> - Your Name: \n",
    "> - Your SCIPER:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c323455f-3c9b-499c-bbb4-5177f86e0b91",
   "metadata": {},
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #b7b7b7ff;background-color:#eeeeeeff;border-radius: 15px;color:black;\">\n",
    "\n",
    "## Rename your notebook with your SciperNo\n",
    "\n",
    "#### üéØ **GOAL:** The final sumbitted file should have the following name: `SciperNo.ipynb`\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48f044d-30ca-41aa-b801-b86360fa00b4",
   "metadata": {},
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #b7b7b7ff;background-color:#eeeeeeff;border-radius: 15px;color:black;\">\n",
    "\n",
    "## THE TASK\n",
    "\n",
    "You are given a set of documents containing relations. These statements have the form `(head, relation, tail)`, where head and tail are entities. For example, the statement \"the window is part of the building\" has the following form: `(\"the window\", \"is part of\", \"the building\")`, with `\"the window\"` and `\"the building\"` being the entities and `\"is part of\"` being the relation pattern of the statement.\n",
    "\n",
    "You will need to:\n",
    "- Explore and understand the given documents.\n",
    "- Extract entities from the documents with syntactic matching based on initial seed relations.\n",
    "- Based on the extracted entities, extract new relations.\n",
    "- Perform entity deduplication and normalization.\n",
    "- Run a full bootstrapping pipeline for relatino extraction computing the confidence in the reliable patterns until convergence.\n",
    "\n",
    "\n",
    "## THE DATA\n",
    "\n",
    "The columns of the provided data are the following:\n",
    "\n",
    "- `document`: the text of a document\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aadb3e0-979f-46c8-8e43-764ee4ceed41",
   "metadata": {},
   "source": [
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #b7b7b7ff;background-color:#eeeeeeff;border-radius: 15px;color:black;\">\n",
    "\n",
    "#### Structure of the exam & Quick access\n",
    "\n",
    "- [PART 1: Data descriptives](#part1)\n",
    "    - [1.1 Compute the size of the dataset and the average, max and min document length in the dataset](#part11)\n",
    "    - [1.2 Print the 5 tokens that appear most often](#part12)\n",
    "\n",
    "- [PART 2: Entity and relation extraction](#part2)\n",
    "    - [2.1 Based on the seed relation pattern, extract the entities for each document using string matching.](#part21)\n",
    "    - [2.2 Based on the extracted entites, extract new relation patterns for each document](#part22)\n",
    "    - [2.3 Obtain the unique entities and relation patterns.](#part23)\n",
    "\n",
    "- [PART 3: Perform entity resolution and normalize the entities found](#part3)\n",
    "     - [3.1 Encode entities.](#part31)\n",
    "     - [3.2 Cluster entity encodings.](#part32)\n",
    "     - [3.3 Normalize extracted entities based on the clusters.](#part33)\n",
    "\n",
    "- [PART 4: Use Bootstrapping for relation extraction](#part4)\n",
    "    - [4.1 Create a function that computes the log confidence of an extracted relation pattern and a function that computes the confidence of an extracted statement..](#part41)\n",
    "    - [4.2 Run the bootstrap pipeline for one iteration.](#part42)\n",
    "    - [4.3 Run the bootstrap pipeline until convergence (no new relation patterns detected).](#part43)\n",
    " \n",
    "- [PART 5: Follow-up questions](#part5)\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef9ea6f-735f-4f05-9a76-71d71f9113d9",
   "metadata": {},
   "source": [
    "### Answer the **MCQ questions on moodle** before submitting. \n",
    "### You can find them here: https://moodle.epfl.ch/mod/quiz/view.php?id=1320882"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63807bae-c7f5-4a40-99d3-a6478f5588d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### üçÄ GOOD LUCK üçÄ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb5a817-1ed5-4f38-a170-9607b59f4cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3cbf37-e95f-473c-bf76-9a324ebcd7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf778b4-423f-417e-b1c1-5fb2aa987250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings to be used in this exam\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f388898-fa96-4e17-97eb-e6a8b85de987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read input file\n",
    "documents = pd.read_json('documents.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323aecbb-1263-476c-85e1-00205e4670cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca6db65-745a-4591-88e6-6b99e3a9a454",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d942b3cb-5d58-48c9-97dd-2f6489054c6c",
   "metadata": {},
   "source": [
    "<a id='part1'></a>\n",
    "\n",
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #0b5394ff;background-color:#3d85c6ff;border-radius: 15px;color:white;\">\n",
    "\n",
    "## 1. Data Descriptives\n",
    "\n",
    "#### üéØ **GOAL:** Understand the dataset by exploring data statistics.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6967d770-77ce-40f7-a34e-25655e0c7f6c",
   "metadata": {},
   "source": [
    "<a id='part11'></a>\n",
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #0b5394ff; background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "#### **1.1** Compute the size of the dataset and the average, max and min document length in the dataset.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16cfa5e-0b02-4b41-95d6-10fff75c1079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_statistics(documents):\n",
    "    \"\"\"\n",
    "    Compute the following statistics of the input documents:\n",
    "    - average length (number of words)\n",
    "    - min and max lengths\n",
    "    - std of the lengths\n",
    "    \n",
    "    :param documents: list of str with the documents.\n",
    "    return: mean and std\n",
    "    \"\"\"\n",
    "\n",
    "    # --------------\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    \n",
    "    # --------------\n",
    "\n",
    "    return (avg_document_length, std_document_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4257838e-11ec-4357-bd4d-387ce1c9b647",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_statistics(documents['document'].values)\n",
    "print('\\n'*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cafc3c-7f2d-4ea7-9dd5-7192fe052985",
   "metadata": {},
   "source": [
    "<a id='part12'></a>\n",
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #0b5394ff; background-color:#eff7fe;border-radius: 15px;\">\n",
    "\n",
    "#### **1.2** Print the 5 tokens that appear most often.\n",
    "\n",
    "_Remove stopwords before computing the top 5 tokens._\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda8c2f5-a61d-4958-ad4f-656c62206da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_tokens(documents):\n",
    "    \"\"\"\n",
    "    Compute the 5 most frequent tokens.\n",
    "\n",
    "    :param documents: list of str with the documents.\n",
    "    return: \n",
    "        - dict with the 5 most frequent tokens along with their counts\n",
    "        - list of str, of all the tokens found in the documents\n",
    "    \"\"\"\n",
    "    stop_words = list(stopwords.words('english'))\n",
    "    # --------------\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    \n",
    "    # --------------\n",
    "    \n",
    "    return top5,  tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4979f821-c58a-4819-92bd-45f353a05177",
   "metadata": {},
   "outputs": [],
   "source": [
    "top5, tokens = top_tokens(documents['document'].values)\n",
    "print('Number of tokens: {}'.format(len(tokens)))\n",
    "print()\n",
    "print('5 most frequent tokens:')\n",
    "for top in top5:\n",
    "    print(top)\n",
    "\n",
    "print('\\n'*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbe91f2-df89-4be3-917c-3c2624d837f1",
   "metadata": {},
   "source": [
    "<a id='part2'></a>\n",
    "\n",
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #38761dff;background-color:#6aa84fff;border-radius: 15px;color:white;\">\n",
    "\n",
    "## 2. Entity and relation extraction\n",
    "\n",
    "#### üéØ GOAL: Extract the entities and relations from the documents based on the seed relation pattern.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6114ee97-8802-4396-ad3b-d68bcada8494",
   "metadata": {},
   "source": [
    "<a id='part21'></a>\n",
    "<div style=\"padding:15px 20px 20px 20px;border-left:3px solid #38761dff;background-color:#e4fae4;border-radius: 15px;\">\n",
    "\n",
    "#### **2.1:** Based on seed relation patterns, extract the entities for each document using string matching.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0879ee2f-17b0-4f6e-852c-36615082667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract entities relations on seed patterns\n",
    "def extract_entities(documents, relations):\n",
    "    \"\"\"   \n",
    "    Extracts the head (up to 4 words before) and tail (up to 4 words after) \n",
    "    of a given relation pattern in a sentence. The function should return the unique entities.\n",
    "\n",
    "    :param documents: list of str, with the text of the documents (statements)\n",
    "    :param relations: list of str, with the seed relations\n",
    "    return: list of tuples: A list of tuples containing the head and tail as strings, or (None, None) if the relation is not found.\n",
    "    \"\"\"\n",
    "\n",
    "    extracted_entities = []\n",
    "    # --------------\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # --------------\n",
    "    return extracted_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbc7344-3396-4b67-90ac-59e6abaa1fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test entity extraction\n",
    "test_seed = [\"is part of\"]\n",
    "\n",
    "test_documents = [\n",
    "    \"the table is part of the office\",\n",
    "    \"tables can be found in offices\",\n",
    "]\n",
    "test_extracted_patterns = extract_entities(test_documents, test_seed)\n",
    "test_extracted_patterns\n",
    "\n",
    "# EXPECTED OUTPUT:\n",
    "# [('the table', 'the office')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20662713-8620-4f88-9be9-57dd3c2af55a",
   "metadata": {},
   "source": [
    "<a id='part22'></a>\n",
    "<div style=\"padding:15px 20px 20px 20px;border-left:3px solid #38761dff;background-color:#e4fae4;border-radius: 15px;\">\n",
    "\n",
    "#### **2.2:** Based on the extracted entites, extract new relation patterns for each document.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8c02b3-b593-4360-84e5-998ec14568d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_relations(documents, entities):\n",
    "    \"\"\"  \n",
    "    Extracts the relation given a pair of head and tail entities.\n",
    "    The function should return the unique relations.\n",
    "\n",
    "    :param documents: list of str, with the text of the documents (statements)\n",
    "    :param entities: list of tuples of str, with the entity pairs.\n",
    "    return: list of str: A list of the extracted relations.\n",
    "    \"\"\"\n",
    "    # --------------\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # --------------\n",
    "\n",
    "    return relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98adca5-6db7-47f3-960b-8f53dfd50561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test pattern extraction\n",
    "test_seeds = [(\"the table\", \"the office\")]\n",
    "\n",
    "test_documents = [\n",
    "    \"the table is part of the office\",\n",
    "    \"the table can be found in the office\",\n",
    "]\n",
    "test_extracted_patterns = extract_relations(test_documents, test_seeds)\n",
    "test_extracted_patterns\n",
    "\n",
    "# EXPECTED OUTPUT:\n",
    "# ['is part of', 'can be found in']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abebdf6-65d9-4aaa-8b59-5a41939908c5",
   "metadata": {},
   "source": [
    "<a id='part23'></a>\n",
    "<div style=\"padding:15px 20px 20px 20px;border-left:3px solid #38761dff;background-color:#e4fae4;border-radius: 15px;\">\n",
    "\n",
    "#### **2.3:** Obtain the unique entities and relation patterns.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b015c72-d711-46f7-abd6-abe58d36dae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_unique_entities(entity_pairs):\n",
    "    \"\"\"\n",
    "    Return a set of the unique entities found in entity pairs.\n",
    "\n",
    "    :param entity_pairs: list of tuples of str, with the entity pairs.\n",
    "    return: set of str, with the unique entities found in entity pairs\n",
    "    \"\"\"\n",
    "    # --------------\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # --------------\n",
    "    return unique_entities\n",
    "\n",
    "\n",
    "def find_unique_relations(relations):\n",
    "    \"\"\"\n",
    "    Return a set of unique relations. \n",
    "\n",
    "    :param relations: list of str, with the relations\n",
    "    return: set of str, with the unique relations\n",
    "    \"\"\"\n",
    "    # --------------\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # --------------\n",
    "    return unique_relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927f3624-83e9-4c00-8914-a3c676c0ae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test above functionality\n",
    "test_entities = [('the table', 'the office'), ('the table', 'the building')]\n",
    "test_relations = ['is part of', 'can be found in', 'is part of', '']\n",
    "print(find_unique_entities(test_entities))\n",
    "print(find_unique_relations(test_relations))\n",
    "\n",
    "# EXPECTED OUTPUT:\n",
    "# {'the office', 'the table', 'the building'}\n",
    "# {'can be found in', 'is part of'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b380bfc-0789-4e5e-8bac-ce52dcf15a30",
   "metadata": {},
   "source": [
    "<a id='part3'></a>\n",
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #b45f06ff;background-color:#e69138ff;border-radius: 15px;color:white;\">\n",
    "\n",
    "## 3. Perform entity resolution and normalize the entities found.\n",
    "\n",
    "#### üéØ GOAL: Create one reference string for semantically similar entities (entity normalization).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8758ec21-58a0-4a49-aaee-4eb63c9a8046",
   "metadata": {},
   "source": [
    "<a id='part31'></a>\n",
    "<div style=\"padding:15px 20px 20px 20px;border-left:3px solid #b45f06ff;background-color:#fce5cdff;border-radius: 15px;\">\n",
    "\n",
    "#### **3.1:** Encode entities.\n",
    "\n",
    "_Use the SentenceTransformer model instantiated above_\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d06155-c56b-4791-88e4-ed8da9ce9901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_entities(entities, model):\n",
    "    \"\"\"\n",
    "    For each entity, compute the embedding vectors.\n",
    "\n",
    "    :param entities: list str, with the entities. \n",
    "    :param model: SentenceTransformer model object\n",
    "    return: dict with keys the entities and values the embedding vector for each entity.\n",
    "    \"\"\"\n",
    "    # --------------\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    \n",
    "    # --------------\n",
    "    return encodings_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb73cee-3cd2-40c9-bc76-ff3f97d95309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test entity encoding\n",
    "test_entities = [\"teacher\", \"teachers\", \"doctor\", \"patient\"]\n",
    "\n",
    "test_encodings = encode_entities(test_entities, model)\n",
    "print(test_encodings.keys())\n",
    "test_encodings['teacher'].shape\n",
    "\n",
    "# EXPECTED OUTPUT:\n",
    "# dict_keys(['teacher', 'teachers', 'doctor', 'patient'])\n",
    "# (384,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51414ec-ce34-4a97-87d5-d78d22778cf6",
   "metadata": {},
   "source": [
    "<a id='part32'></a>\n",
    "<div style=\"padding:15px 20px 20px 20px;border-left:3px solid #b45f06ff;background-color:#fce5cdff;border-radius: 15px;\">\n",
    "\n",
    "#### **3.2:** Cluster entity encodings.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f3e7cb-0377-437d-b789-43cc8b13bf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_strings_by_similarity(embeddings_dict, threshold):\n",
    "    \"\"\"\n",
    "    Cluster strings based on their embedding similarity using a given threshold.\n",
    "    \n",
    "    :param embeddings_dict: Dictionary {string: embedding (numpy array)}.\n",
    "    :param threshold: Similarity threshold (float, e.g., 0.8).\n",
    "    :return: List of clusters, where each cluster is a list of strings.\n",
    "    \"\"\"\n",
    "    strings = list(embeddings_dict.keys())\n",
    "    embeddings = np.array(list(embeddings_dict.values()))\n",
    "    \n",
    "    # Compute the pairwise cosine similarity matrix\n",
    "    similarity_matrix = cosine_similarity(embeddings)\n",
    "    \n",
    "    # Create a graph as an adjacency list\n",
    "    graph = defaultdict(set)\n",
    "    for i in range(len(strings)):\n",
    "        for j in range(i + 1, len(strings)):\n",
    "            if similarity_matrix[i, j] > threshold:\n",
    "                graph[strings[i]].add(strings[j])\n",
    "                graph[strings[j]].add(strings[i])\n",
    "    \n",
    "    # Perform a graph traversal to find connected components (clusters)\n",
    "    visited = set()\n",
    "    clusters = []\n",
    "\n",
    "    def dfs(node, cluster):\n",
    "        visited.add(node)\n",
    "        cluster.append(node)\n",
    "        for neighbor in graph[node]:\n",
    "            if neighbor not in visited:\n",
    "                dfs(neighbor, cluster)\n",
    "\n",
    "    for string in strings:\n",
    "        if string not in visited:\n",
    "            cluster = []\n",
    "            dfs(string, cluster)\n",
    "            clusters.append(cluster)\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778f90fc-b725-4ce2-960d-267da71e3120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test entity encoding\n",
    "test_clusters = cluster_strings_by_similarity(test_encodings, 0.8)\n",
    "test_clusters\n",
    "\n",
    "# EXPECTED OUTPUT:\n",
    "# [['teacher', 'teachers'], ['doctor'], ['patient']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb08a6bd-95d0-459a-b090-5386c282f50d",
   "metadata": {},
   "source": [
    "<a id='part33'></a>\n",
    "<div style=\"padding:15px 20px 20px 20px;border-left:3px solid #b45f06ff;background-color:#fce5cdff;border-radius: 15px;\">\n",
    "\n",
    "#### **3.3:** Normalize extracted entities based on the clusters.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406faf60-f7d1-4e78-857e-5244fa33e528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(clusters, documents, entity_pairs):\n",
    "    \"\"\"\n",
    "    Replace the entities in the same cluster with only one corresponding token. Apply normalization to both sentences and entity pairs.\n",
    "    E.g.\n",
    "    cluster: ['teacher', 'teachers'] \n",
    "    input: ['the teacher is working at school', \n",
    "            'teachers work the school']\n",
    "\n",
    "    output: ['the teacher is working at school', \n",
    "             'teacher work the school']\n",
    "    or\n",
    "    output: ['the teachers is working at school', \n",
    "             'teachers work the school']   \n",
    "\n",
    "    :param clusters: list of lists of clusters\n",
    "    :param documents: list of str, with the text of the documents (statements)\n",
    "    :param entity_pairs: list of tuples of str, with the entity pairs.\n",
    "    return: \n",
    "        - list of str, with the text of the documents (statements) with normalized entities\n",
    "        - list of tuples of str, with the normalized entity pairs.\n",
    "    \"\"\"\n",
    "    normalize = dict()\n",
    "    for c in clusters:\n",
    "        w0 = c[0]\n",
    "        for w in c:\n",
    "            normalize[w] = w0\n",
    "\n",
    "    normalized_sentences = []\n",
    "    for sentence in documents:\n",
    "        for key, value in normalize.items():\n",
    "            sentence = sentence.replace(key, value)\n",
    "        normalized_sentences.append(sentence.strip())\n",
    "\n",
    "    normalized_entity_pairs = []\n",
    "    for entity_pair in entity_pairs:\n",
    "        head = normalize.get(entity_pair[0], entity_pair[0])\n",
    "        tail = normalize.get(entity_pair[1], entity_pair[1])\n",
    "        normalized_entity_pairs.append((head, tail))       \n",
    "\n",
    "    return normalized_sentences, normalized_entity_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ac27b4-70e9-41bf-a7be-2a0f8fd7bed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test normalized entity functionality\n",
    "test_documents = ['the teacher is part of the school', \n",
    "                  'teachers can be found at the schools']\n",
    "\n",
    "test_entities = [('the teacher', 'the school'), \n",
    "                  ('teachers', 'the schools')]\n",
    "\n",
    "normalized_test_docs, normalized_test_entities = normalize(test_clusters, test_documents, test_entities)\n",
    "\n",
    "for d, e in zip(normalized_test_docs, normalized_test_entities):\n",
    "    print(d)\n",
    "    print(e)\n",
    "    print()\n",
    "\n",
    "print('\\n'*1)\n",
    "\n",
    "# EXPECTED OUTPUT:\n",
    "# the teacher is part of the school\n",
    "# ('the teacher', 'the school')\n",
    "\n",
    "# teacher can be found at the schools\n",
    "# ('teacher', 'the schools')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8394a26-e4c8-4e60-b8da-708f5872a683",
   "metadata": {},
   "source": [
    "<a id='part4'></a>\n",
    "\n",
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #351c75ff;background-color:#674ea7ff;border-radius: 15px;color:white;\">\n",
    "\n",
    "## 4. Use Bootstrapping for relation extraction.\n",
    "\n",
    "#### üéØ GOAL: Use the above functions to iteratively extract new relation patterns until convergence. Select relation patterns based on confirmed statements (entity pairs) and based on the log confidence threshold. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284ad3e4-726f-47c1-950c-eac6137b19bf",
   "metadata": {},
   "source": [
    "<a id='part41'></a>\n",
    "<div style=\"padding:15px 20px 20px 20px;border-left:3px solid #351c75ff;background-color:#d9d2e9ff;border-radius: 20px;\">\n",
    "\n",
    "#### **4.1:** Create a function that computes the log confidence of an extracted relation pattern and a function that computes the confidence of an extracted statement.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154cec7c-7e7d-4e1f-9946-3c2b5dd545a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confidence(new_entities, confirmed_entities):\n",
    "    \"\"\"\n",
    "    Compute the log confidence of a relation.\n",
    "\n",
    "    :param new_entities: list of tuples of str, with entity pairs. \n",
    "    :param confirmed_entities: list of tuples of str, with entity pairs. \n",
    "    return: float with the confidence score\n",
    "    \"\"\"\n",
    "    # --------------\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "\n",
    "    # --------------\n",
    "    return confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c3a14d-88ba-4859-973b-5ce0972e0063",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_link = \"is part of\"\n",
    "test_confirmed_entities = [('the table', 'the office')]\n",
    "test_new_entities = [('the table', 'the office'), ('the table', 'the kitchen')]\n",
    "print(get_confidence(test_new_entities, test_confirmed_entities))\n",
    "print('\\n'*1)\n",
    "\n",
    "# EXPECTED OUTPUT:\n",
    "# 0.34657359027997264"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfca411-35cf-4880-8a07-e8e2764d030a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statement_confidence(sentences, entity_pair, relations):\n",
    "    \"\"\"\n",
    "    Compute the confidence of a statement (entity pair and relation).\n",
    "\n",
    "    :param sentences: list of str, with the text of the documents (statements)\n",
    "    :param entity_pair: tuples of str, the entity pair for which confidence is computed\n",
    "    :param relations: dict with keys the known relations and values their confidence\n",
    "    return: float, the confidence of a statement\n",
    "    \"\"\"\n",
    "    # --------------\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    \n",
    "    # --------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d8c363-4d9b-443f-9940-abf4adbcfea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pair = (\"the table\", \"the office\")\n",
    "\n",
    "test_documents = [\n",
    "    \"the table is part of the office\",\n",
    "    \"the table can be found in the office\",\n",
    "]\n",
    "\n",
    "test_relations = {\"is part of\": 0.7,\"can be found in\": 0.6}\n",
    "\n",
    "get_statement_confidence(test_documents, test_pair, test_relations)\n",
    "\n",
    "# EXPECTED OUTPUT:\n",
    "# 0.88"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6b4be1-a4ca-44c4-845a-2fc86b0b6d53",
   "metadata": {},
   "source": [
    "<a id='part42'></a>\n",
    "<div style=\"padding:15px 20px 20px 20px;border-left:3px solid #351c75ff;background-color:#d9d2e9ff;border-radius: 20px;\">\n",
    "\n",
    "#### **4.2:** Run the bootstrap pipeline for one iteration.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c9f570-dd11-422b-8e86-9c29f3614ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_relations_and_statements(sentences, \n",
    "                                     entity_pairs, \n",
    "                                     relations, \n",
    "                                     t=0.5,\n",
    "                                     sim=0.7,\n",
    "                                     t_stat = 0.5):\n",
    "    \"\"\"\n",
    "    :param sentences: list of str, non-normalized sentences to extract relations.\n",
    "    :param entity_pairs: list of tuples of str, of the confirmed entity pairs\n",
    "    :param relations: list of str, confirmed relation patterns\n",
    "    :param t: float, threshold for log confidence to retain relation pattern.\n",
    "    :param sim: float, threshold for entity similarity.\n",
    "    :param t_stat: float, threshold for confidence in statements.\n",
    "    return: \n",
    "        - dict with relations as keys and their confidence as values\n",
    "        - list of tuples of str, with the entity pairs\n",
    "    \"\"\"\n",
    "    # --------------\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # Step 1: normalize documents and entities based on the confirmed entity pairs\n",
    "    \n",
    "    \n",
    "    # Step 2: for the confirmed entity pairs, extract all the relation patterns in the documents\n",
    "    \n",
    "\n",
    "    # Step 3: for the extracted relation patterns, compute their confidence \n",
    "    \n",
    "\n",
    "    # Step 4: keep only the relation patterns that exceed the confidence threshold \n",
    "    \n",
    "\n",
    "    # Step 5: for the (non-normalized) entity pairs matching the selected relation patterns, compute confidence in the statement\n",
    "    # select those entity pairs that have statement confidence above the threshold as confirmed statements\n",
    "\n",
    "    \n",
    "    # --------------\n",
    "    return filtered_relations, filtered_statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb40cf8-847b-4cfa-8c91-991ca18aedb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "test_seeds = [\"is part of\"]\n",
    "\n",
    "test_documents = [\n",
    "    \"the table is part of the office\",\n",
    "    \"the table is in the office\",\n",
    "    \"the table is in the office\",\n",
    "]\n",
    "\n",
    "entity_pairs = extract_entities(test_documents, test_seeds)\n",
    "get_top_relations_and_statements(test_documents, entity_pairs, test_seeds, 0.5, 0.8, 0.5)\n",
    "\n",
    "# EXPECTED OUTPUT:\n",
    "# ({'is in': 0.6931471805599453}, [('the table', 'the office')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eef999f-157f-41b3-84eb-05b7f4005d29",
   "metadata": {},
   "source": [
    "<a id='part43'></a>\n",
    "<div style=\"padding:15px 20px 20px 20px;border-left:3px solid #351c75ff;background-color:#d9d2e9ff;border-radius: 20px;\">\n",
    "\n",
    "#### **4.3:** Run the bootstrap pipeline until convergence (no new relation patterns detected).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8230c893-44f4-4f92-8c61-8534c9997a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursice discovery of new relation patterns and confirmed entity pairs, don't change this cell\n",
    "\n",
    "def run_bootstrap(sentences, seed_relation, t, sim, stat):\n",
    "    top_relations = {1: [seed_relation]}\n",
    "    confirmed_entity_pairs = extract_entities(sentences, [seed_relation])\n",
    "    new_top_links = []\n",
    "    \n",
    "    i=1\n",
    "    while True:\n",
    "        \n",
    "        old_relations = new_top_links\n",
    "        old_pairs = confirmed_entity_pairs\n",
    "        new_top_links_d, confirmed_entity_pairs = get_top_relations_and_statements(sentences, confirmed_entity_pairs, \n",
    "                                                                                   top_relations[i], \n",
    "                                                                                   t, \n",
    "                                                                                   sim, \n",
    "                                                                                   stat)\n",
    "        new_top_links = list(new_top_links_d.keys())\n",
    "\n",
    "        # Remove links that are already extracted\n",
    "        new_items = [link for link in new_top_links if link not in top_relations[i]]\n",
    "\n",
    "        # If no new links were added, stop the loop\n",
    "        if not new_items:\n",
    "            break\n",
    "\n",
    "        # Add the new links to the extracted list\n",
    "        all_links = top_relations[i] + new_items\n",
    "        i += 1\n",
    "        top_relations[i] = all_links\n",
    "\n",
    "    return top_relations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76803c51-9123-4a8b-ac5f-1ac93f3dec31",
   "metadata": {},
   "source": [
    "#### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12babefc-566a-4c7a-afe1-4e2300770c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.5, 0.7, 0.9] \n",
    "similarities = [0.5, 0.7, 1]\n",
    "statement_thresholds = [0.5, 0.7, 0.9]\n",
    "\n",
    "thresholds = [0.5]\n",
    "\n",
    "res = list()\n",
    "for similarity in similarities:\n",
    "    for threshold in thresholds:\n",
    "        for statement_threshold in statement_thresholds:\n",
    "        \n",
    "            run = run_bootstrap(documents['document'].values, 'is part of', t = threshold, sim = similarity, stat = statement_threshold)\n",
    "            number_of_runs = len(run.keys())\n",
    "            res.append({'similarity': similarity, 'threshold': threshold, 'stat_threshold': statement_threshold,\n",
    "                        'number_of_runs': number_of_runs, 'extracted_relations': run[number_of_runs], \n",
    "                        'extracted_relations_count': len(run[number_of_runs])})\n",
    "results = pd.DataFrame(res)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e6bbb4-8da2-4dd7-bb11-096c8a7cc197",
   "metadata": {},
   "source": [
    "<a id='part5'></a>\n",
    "\n",
    "<div style=\"padding:15px 15px 15px 15px;border-left:3px solid #bf9000ff;background-color:#f1c232ff;border-radius: 15px;color:white;\">\n",
    "\n",
    "## 5. Follow-up questions\n",
    "\n",
    "Based on the previous experiments, answer the following questions.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e800e363-8190-48a5-b1c1-166d7927812d",
   "metadata": {},
   "source": [
    "<a id='part51'></a>\n",
    "<div style=\"padding:15px 20px 20px 20px;border-left:3px solid #bf9000ff;background-color:#fff2ccff;border-radius: 20px;\">\n",
    "\n",
    "#### **5.1:** Discuss the impact of the confidence threshold. Does increasing the threshold always result in fewer detected relation patterns?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a9ebe7-68e6-4ad0-80d4-9cbca3757884",
   "metadata": {},
   "source": [
    "> Your answer here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a094db89-d57a-41d8-8607-a0810984c64c",
   "metadata": {},
   "source": [
    "<a id='part52'></a>\n",
    "<div style=\"padding:15px 20px 20px 20px;border-left:3px solid #bf9000ff;background-color:#fff2ccff;border-radius: 20px;\">\n",
    "\n",
    "#### **5.2:** Discuss the impact of the entity similarity threshold. Does decreasing the threshold always result in more detected relation patterns?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f779af-67f8-4e59-b3ba-c3911b8893e8",
   "metadata": {},
   "source": [
    "> Your answer here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133314ad-2e7e-4aef-91c4-970731f668cb",
   "metadata": {},
   "source": [
    "<a id='part53'></a>\n",
    "<div style=\"padding:15px 20px 20px 20px;border-left:3px solid #bf9000ff;background-color:#fff2ccff;border-radius: 20px;\">\n",
    "\n",
    "#### **5.3:** With the same parameter settings, does the choice of the seed relation pattern influence the final result?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244f53c7-3831-4d7b-bc25-393d8e9004e5",
   "metadata": {},
   "source": [
    "> Your answer here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a3f458-5574-4d19-8434-f02cede9c02b",
   "metadata": {},
   "source": [
    "<a id='part54'></a>\n",
    "<div style=\"padding:15px 20px 20px 20px;border-left:3px solid #bf9000ff;background-color:#fff2ccff;border-radius: 20px;\">\n",
    "\n",
    "#### **5.4:** Can you explain why it is not unreasonable that the relation \"is less expensive than\" can be confused with \"is part of\".\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02231c65-db04-43fb-b60d-f14c01032b70",
   "metadata": {},
   "source": [
    "> Your answer here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee002fd-9920-4978-a1d8-a3faad3b7fa9",
   "metadata": {},
   "source": [
    "## üîö END OF EXAM\n",
    "> Don't forget to change the name of the submitted file to your SciperNo as the file name before submitting.\n",
    "\n",
    "<a id='submit'></a>\n",
    "#### [SUBMIT HERE](https://moodle.epfl.ch/mod/assign/view.php?id=1321125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620be2ae-6060-46d2-ba93-1513c3d5ba00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
